# Copyright (C) 2017 NVIDIA Corporation.  All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).

# logger options
image_save_iter: 5000         # How often do you want to save output images during training
snapshot_save_iter: 2000      # How often do you want to save trained models
snapshot_test_epoch: 200       # How often do you want to display output images during training
log_iter: 2                 # How often do you want to log the training stats
display_size: 8               # How many images do you want to display each time

# optimization options
max_iter: 10000               # maximum number of training iterations
batch_size: 2                 # batch size
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
weight_decay: 0.00001         # weight decay
lr_policy: step               # learning rate scheduler
step_size: 3000               # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss
sup_w: 1                      # weight of supervised loss
recon_x_w: 10                 # weight of image reconstruction loss
recon_s_w: 1                  # weight of style reconstruction loss
recon_c_w: 1                  # weight of content reconstruction loss
recon_x_cyc_w: 1              # weight of explicit style augmented cycle consistency loss
vgg_w: 0                      # weight of domain-invariant perceptual loss

# model options
gen:
  dim: 32                     # number of filters in the bottommost layer
  mlp_dim: 32                # number of filters in MLP
  style_dim: 8                # length of style code
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder
  n_res: 2                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
dis:
  dim: 32                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 2                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan]
  num_scales: 3               # number of scales
  pad_type: reflect           # padding type [zero/reflect]
sup:
#   arch: unet                  # architecture of segmentation network
  dim: 128                    # number of filters in the bottommost layer
  
# data options
n_datasets: 3                                       # number of datasets used in training
n_classes: 4                                        # number of classes in supervised task
input_dim: 1                                        # number of image channels [1/3]
num_workers: 8                                      # number of data loading threads
resize_height: 256                                  # first resize image to this height
resize_width: 256                                   # first resize image to this width
data_root: ../CADCOVID/Datasets_CoDAGANs/     # Dataset folder location.
label_use: [True,True,True]
